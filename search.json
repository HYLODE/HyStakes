[
  {
    "objectID": "vignettes/hello-world.html",
    "href": "vignettes/hello-world.html",
    "title": "HyStakes",
    "section": "",
    "text": "Use this to confirm that your set-up is working. It should open and run from within VSCode, and it should be using the hystakes kernel.\n\nprint('Hello World!')\n\nHello World!"
  },
  {
    "objectID": "vignettes/prepare-synthetic-data.html",
    "href": "vignettes/prepare-synthetic-data.html",
    "title": "HyStakes",
    "section": "",
    "text": "Steve Harris\n2022-09-11\n\nWe need synthetic data.\nWe will inspect live data in this notebook, and then derive a short script that will generate suitable dummy data.\nNOTE\nThis notebook will be be run manually.\nThat should happen from the project root directory where the readme.md and the .env file are stored.\nThe following changes to the project root assuming that the notebook kernel is normally starting from the same directory as the notebook itself.\n\n%cd ../..\n\n/data/hymind/home/steve/HyStakes\n\n\n\nimport os\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import poisson, lognorm\nimport sqlalchemy as sa\n\n\n%matplotlib inline\n\n\n\nLoad environment variables and set-up SQLAlchemy connection engine for the EMAP Star\n\nload_dotenv(dotenv_path=\".env\")\ntry:\n    assert os.getenv(\"DOTENV_FILE_EXISTS\") == 'TRUE'\nexcept AssertionError:\n    print(\"!!! ERROR: check that the .env file exists at the top level of the project\")\n    print(\"!!! ERROR: check that the relative path is correct\")\n\n\n# Construct the PostgreSQL connection\nuds_host = os.getenv('EMAP_DB_HOST')\nuds_name = os.getenv('EMAP_DB_NAME')\nuds_port = os.getenv('EMAP_DB_PORT')\nuds_user = os.getenv('EMAP_DB_USER')\nuds_passwd = os.getenv('EMAP_DB_PASSWORD')\n\nemapdb_engine = sa.create_engine(f'postgresql://{uds_user}:{uds_passwd}@{uds_host}:{uds_port}/{uds_name}')\n\n\n\n\nHere’s the very long query that I built.\nIt selects all patients on tower wards 2 weeks ago (336 hours), and then finds the age (rounded) and the last heart rate. The remaining data has no identifiers.\n\nSELECT\n left(md5(lv.hospital_visit_id::TEXT), 6) id\n--,lv.location_visit_id\n--,lv.admission_datetime admit_dt_bed\n--,lv.discharge_datetime disch_dt_bed\n--,hv.admission_datetime admit_dt_hosp\n--,hv.discharge_datetime disch_dt_hosp\n,ROUND(EXTRACT(epoch FROM \n    (hv.discharge_datetime - (NOW() - '336 HOURS'::INTERVAL)\n    ))/3600) hours_to_discharge\n--,hv.discharge_destination\n--,hv.patient_class\n--,lo.location_string\n,dept.name department\n\n-- include age rounded to 5\n, ROUND(DATE_PART('year',AGE(cd.date_of_birth ))/5) * 5 AGE\n\n-- add last heart rate\n,hr.value_as_real pulse\n--,hr.observation_datetime\n\n\nFROM star.location_visit lv\nLEFT JOIN star.location lo ON lv.location_id = lo.location_id\nLEFT JOIN star.department dept ON lo.department_id = dept.department_id \nLEFT JOIN star.hospital_visit hv ON lv.hospital_visit_id = hv.hospital_visit_id\nLEFT JOIN star.core_demographic cd ON hv.mrn_id = cd.mrn_id\nLEFT JOIN (\n    WITH obs AS (\n        SELECT\n\n         vo.visit_observation_id\n        ,vo.hospital_visit_id\n        ,vo.observation_datetime\n        ,vo.value_as_real\n        ,ot.name\n\n        FROM star.visit_observation vo\n        LEFT JOIN star.visit_observation_type ot ON vo.visit_observation_type_id = ot.visit_observation_type_id\n        WHERE \n        ot.id_in_application = '8' -- heart rate\n        AND\n        vo.observation_datetime < NOW() - '336 HOURS'::INTERVAL \n        AND\n        vo.observation_datetime > NOW() - '360 HOURS'::INTERVAL \n    ),\n    obs_tail AS (\n        SELECT \n         obs.*\n        ,row_number() over (partition BY obs.hospital_visit_id ORDER BY obs.observation_datetime DESC) obs_tail\n        FROM obs\n    )\n    SELECT \n     visit_observation_id\n    ,hospital_visit_id\n    ,observation_datetime\n    ,value_as_real\n    ,NAME\n    FROM obs_tail \n    WHERE obs_tail = 1\n) hr -- heart rate\nON lv.hospital_visit_id = hr.hospital_visit_id\n\nWHERE \ndept.name IN (\n'UCH T03 INTENSIVE CARE'\n,'UCH SDEC'\n,'UCH T01 ACUTE MEDICAL'\n,'UCH T01 ENHANCED CARE'\n,'UCH T06 HEAD (T06H)'\n,'UCH T06 CENTRAL (T06C)'\n,'UCH T06 SOUTH PACU'\n,'UCH T06 GYNAE (T06G)'\n,'UCH T07 NORTH (T07N)'\n,'UCH T07 CV SURGE'\n,'UCH T07 SOUTH'\n,'UCH T07 SOUTH (T07S)'\n,'UCH T07 HDRU'\n,'UCH T08 NORTH (T08N)'\n,'UCH T08 SOUTH (T08S)'\n,'UCH T08S ARCU'\n,'UCH T09 SOUTH (T09S)'\n,'UCH T09 NORTH (T09N)'\n,'UCH T09 CENTRAL (T09C)'\n,'UCH T10 SOUTH (T10S)'\n,'UCH T10 NORTH (T10N)'\n,'UCH T10 MED (T10M)'\n,'UCH T11 SOUTH (T11S)'\n,'UCH T11 NORTH (T11N)'\n,'UCH T11 EAST (T11E)'\n,'UCH T11 NORTH (T11NO)'\n,'UCH T12 SOUTH (T12S)'\n,'UCH T12 NORTH (T12N)'\n,'UCH T13 SOUTH (T13S)'\n,'UCH T13 NORTH ONCOLOGY'\n,'UCH T13 NORTH (T13N)'\n,'UCH T14 NORTH TRAUMA'\n,'UCH T14 NORTH (T14N)'\n,'UCH T14 SOUTH ASU'\n,'UCH T14 SOUTH (T14S)'\n,'UCH T15 SOUTH DECANT'\n,'UCH T15 SOUTH (T15S)'\n,'UCH T15 NORTH (T15N)'\n,'UCH T15 NORTH DECANT'\n,'UCH T16 NORTH (T16N)'\n,'UCH T16 SOUTH (T16S)'\n,'UCH T16 SOUTH WINTER'\n\n)\nAND\nlv.admission_datetime < NOW() - '336 HOURS'::INTERVAL \nAND\n    (lv.discharge_datetime > NOW() - '336 HOURS'::INTERVAL \n     OR\n      (lv.discharge_datetime IS NULL AND hv.discharge_datetime IS NULL)\n    )\nAND \nlo.location_string NOT LIKE '%WAIT%'\nAND \nlo.location_string NOT LIKE '%null%'\n;\nTo benefit from syntax highlighting, proper version control and other goodness then we’ll actually load the query from its own file. The list above is there just to improve the flow and readability of this notebook.\n\nq = Path('utils/queries/discharges_dummy.sql').read_text()\n\n# this handles escaping etc (e.g. % in the LIKE clause becomes %%)\nq = sa.text(q)\n\n\ndf = pd.read_sql_query(q, emapdb_engine)\n\nNow inspect the fields\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 444 entries, 0 to 443\nData columns (total 5 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   id                  444 non-null    object \n 1   hours_to_discharge  263 non-null    float64\n 2   department          444 non-null    object \n 3   age                 444 non-null    float64\n 4   pulse               381 non-null    float64\ndtypes: float64(3), object(2)\nmemory usage: 17.5+ KB\n\n\n\n\n\n\n\nPlot the distribution, then pick a distribution and create a simple sample\n\nLoS = df['hours_to_discharge']\nLoS.describe()\n\ncount    263.000000\nmean     108.049430\nstd       82.814341\nmin        1.000000\n25%       43.000000\n50%       86.000000\n75%      157.500000\nmax      332.000000\nName: hours_to_discharge, dtype: float64\n\n\n\nn, bins, patches = plt.hist(LoS, bins=20)\n\n\n\n\nNow generate an empirical distribution that roughly matches as above by sampling with replacement\n\nLoS_sample = LoS.sample(frac=1, replace=True)\nLoS_sample.describe()\n\ncount    263.000000\nmean      96.634981\nstd       80.698500\nmin        1.000000\n25%       40.000000\n50%       68.000000\n75%      138.500000\nmax      305.000000\nName: hours_to_discharge, dtype: float64\n\n\n\nn, bins, patches = plt.hist(LoS_sample, bins=20)\n\n\n\n\n\n\n\nPlot the distribution, then pick a distribution and create a simple sample\n\ndepartment = df['department']\ndepartment.value_counts()\n\nUCH T01 ACUTE MEDICAL     36\nUCH T10 SOUTH (T10S)      35\nUCH T10 NORTH (T10N)      24\nUCH T09 NORTH (T09N)      24\nUCH T13 NORTH ONCOLOGY    24\nUCH SDEC                  23\nUCH T13 SOUTH (T13S)      22\nUCH T08 SOUTH (T08S)      21\nUCH T08 NORTH (T08N)      20\nUCH T09 CENTRAL (T09C)    19\nUCH T03 INTENSIVE CARE    19\nUCH T12 NORTH (T12N)      18\nUCH T14 NORTH TRAUMA      17\nUCH T16 NORTH (T16N)      15\nUCH T07 NORTH (T07N)      15\nUCH T16 SOUTH WINTER      14\nUCH T14 SOUTH ASU         13\nUCH T06 HEAD (T06H)       12\nUCH T12 SOUTH (T12S)      10\nUCH T11 NORTH (T11N)       9\nUCH T01 ENHANCED CARE      9\nUCH T11 SOUTH (T11S)       9\nUCH T07 SOUTH              7\nUCH T06 CENTRAL (T06C)     6\nUCH T14 NORTH (T14N)       4\nUCH T06 SOUTH PACU         4\nUCH T09 SOUTH (T09S)       3\nUCH T06 GYNAE (T06G)       3\nUCH T15 SOUTH (T15S)       2\nUCH T07 SOUTH (T07S)       2\nUCH T10 MED (T10M)         1\nUCH T08S ARCU              1\nUCH T15 NORTH (T15N)       1\nUCH T11 EAST (T11E)        1\nUCH T16 SOUTH (T16S)       1\nName: department, dtype: int64\n\n\n\nX = df.groupby('department')['department'].count()\n\n\nfig, ax = plt.subplots(dpi=1.5*72)\nax.bar(X.index, X.values)\nax.tick_params(axis='x', rotation=90)\nplt.show()\n\n\n\n\nNow generate an empirical distribution that roughly matches as above by sampling with replacement\n\ndepartment_sample =department.sample(frac=1, replace=True)\ndepartment_sample.value_counts()\n\nUCH T01 ACUTE MEDICAL     45\nUCH T10 SOUTH (T10S)      37\nUCH T09 CENTRAL (T09C)    30\nUCH T13 NORTH ONCOLOGY    26\nUCH T10 NORTH (T10N)      26\nUCH T09 NORTH (T09N)      25\nUCH T13 SOUTH (T13S)      23\nUCH T03 INTENSIVE CARE    22\nUCH SDEC                  22\nUCH T07 NORTH (T07N)      21\nUCH T06 HEAD (T06H)       16\nUCH T12 NORTH (T12N)      16\nUCH T16 NORTH (T16N)      16\nUCH T14 SOUTH ASU         14\nUCH T08 SOUTH (T08S)      14\nUCH T14 NORTH TRAUMA      12\nUCH T16 SOUTH WINTER      12\nUCH T08 NORTH (T08N)      11\nUCH T11 NORTH (T11N)      10\nUCH T11 SOUTH (T11S)       7\nUCH T01 ENHANCED CARE      6\nUCH T07 SOUTH              6\nUCH T12 SOUTH (T12S)       5\nUCH T06 SOUTH PACU         5\nUCH T14 NORTH (T14N)       3\nUCH T06 CENTRAL (T06C)     3\nUCH T06 GYNAE (T06G)       3\nUCH T15 SOUTH (T15S)       3\nUCH T07 SOUTH (T07S)       1\nUCH T15 NORTH (T15N)       1\nUCH T16 SOUTH (T16S)       1\nUCH T10 MED (T10M)         1\nUCH T09 SOUTH (T09S)       1\nName: department, dtype: int64\n\n\n\nX_s = department_sample.value_counts()\nX_s = X_s.reindex(X.index)\nfig, ax = plt.subplots(dpi=1.5*72)\nax.bar(X_s.index, X_s.values)\nax.tick_params(axis='x', rotation=90)\nplt.show()\n\n\n\n\n\n\n\nPlot the distribution, then pick a distribution and create a simple sample\n\nage = df['age']\nage.describe()\n\ncount    444.000000\nmean      57.927928\nstd       23.748289\nmin        0.000000\n25%       40.000000\n50%       65.000000\n75%       75.000000\nmax      100.000000\nName: age, dtype: float64\n\n\n\nn, bins, patches = plt.hist(age, bins=20)\n\n\n\n\nNow generate an empirical distribution that roughly matches as above by sampling with replacement\n\nage_sample = age.sample(frac=1, replace=True)\nage_sample.describe()\n\ncount    444.000000\nmean      58.355856\nstd       22.933793\nmin        5.000000\n25%       43.750000\n50%       65.000000\n75%       75.000000\nmax      100.000000\nName: age, dtype: float64\n\n\n\nn, bins, patches = plt.hist(age_sample, bins=20)\n\n\n\n\n\n\n\nPlot the distribution, then pick a distribution and create a simple sample\n\npulse = df['pulse']\npulse.describe()\n\ncount    381.000000\nmean      81.391076\nstd       17.147712\nmin       42.000000\n25%       70.000000\n50%       80.000000\n75%       90.000000\nmax      187.000000\nName: pulse, dtype: float64\n\n\n\nn, bins, patches = plt.hist(pulse, bins=20)\n\n\n\n\nNow generate an empirical distribution that roughly matches as above by sampling with replacement\n\npulse_sample = pulse.sample(frac=1, replace=True)\npulse_sample.describe()\n\ncount    375.000000\nmean      79.696000\nstd       15.435336\nmin       46.000000\n25%       68.500000\n50%       78.000000\n75%       89.000000\nmax      133.000000\nName: pulse, dtype: float64\n\n\n\nn, bins, patches = plt.hist(pulse_sample, bins=20)\n\n\n\n\n\npulse_sample\n\n115     59.0\n363    102.0\n317     72.0\n257     60.0\n265      NaN\n       ...  \n237      NaN\n118     87.0\n47      78.0\n253     63.0\n394     77.0\nName: pulse, Length: 444, dtype: float64\n\n\n\n\n\n\n\nLoS_sample.reset_index(inplace=True, drop=True)\ndepartment_sample.reset_index(inplace=True, drop=True)\nage_sample.reset_index(inplace=True, drop=True)\npulse_sample.reset_index(inplace=True, drop=True)\n\n\ndf_dummy = pd.concat([LoS_sample, department_sample, age_sample, pulse_sample], axis=1)\n\n\ndf_dummy.reset_index(inplace=True)\n\n\ndf_dummy.rename({'index': 'id'}, axis=1, inplace=True)\n\n\ndf_dummy.head()\n\n\n\n\n\n  \n    \n      \n      id\n      hours_to_discharge\n      department\n      age\n      pulse\n    \n  \n  \n    \n      0\n      0\n      42.0\n      UCH T11 NORTH (T11N)\n      60.0\n      59.0\n    \n    \n      1\n      1\n      NaN\n      UCH T03 INTENSIVE CARE\n      65.0\n      102.0\n    \n    \n      2\n      2\n      132.0\n      UCH T13 NORTH ONCOLOGY\n      60.0\n      72.0\n    \n    \n      3\n      3\n      206.0\n      UCH T01 ACUTE MEDICAL\n      10.0\n      60.0\n    \n    \n      4\n      4\n      90.0\n      UCH T11 SOUTH (T11S)\n      65.0\n      NaN\n    \n  \n\n\n\n\nWrite dummy data out. Use sqlite to manage typing etc.\n\nsqlite_engine = sa.create_engine('sqlite:///data/dummy.db')\ndf_dummy.to_sql('discharges', con=sqlite_engine, if_exists='replace')"
  },
  {
    "objectID": "vignettes/uclh-working-with-star.html",
    "href": "vignettes/uclh-working-with-star.html",
    "title": "HyStakes",
    "section": "",
    "text": "A template JupyterNotebook for working with EMAP. The following features of this notebook, and associated files are documented here to minimise the risk of data leaks or other incidents.\n\nUsernames and passwords are stored in a .env file that is excluded from version control. An example file is found at ./.env.example (which is tracked and shared via version control).\n.gitattributes are set to strip JupyterNotebook cells when pushing to GitHub\n\nNOTE\nThis notebook will be be run manually.\nThat should happen from the project root directory where the readme.md and the .env file are stored.\nThe following changes to the project root assuming that the notebook kernel is normally starting from the same directory as the notebook itself.\n\n%cd ../..\n\n\n\nLoad libraries\n\nimport os\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n\n\n\nLoad environment variables and set-up SQLAlchemy connection engine for the EMAP Star\n\nload_dotenv(dotenv_path=\".env\")\ntry:\n    assert os.getenv(\"DOTENV_FILE_EXISTS\") == 'TRUE'\nexcept AssertionError:\n    print(\"!!! ERROR: check that the .env file exists at the top level of the project\")\n    print(\"!!! ERROR: check that the relative path is correct\")\n\n\n# Construct the PostgreSQL connection\nuds_host = os.getenv('EMAP_DB_HOST')\nuds_name = os.getenv('EMAP_DB_NAME')\nuds_port = os.getenv('EMAP_DB_PORT')\nuds_user = os.getenv('EMAP_DB_USER')\nuds_passwd = os.getenv('EMAP_DB_PASSWORD')\n\nemapdb_engine = create_engine(f'postgresql://{uds_user}:{uds_passwd}@{uds_host}:{uds_port}/{uds_name}')\n\n\n\n\nNow use the connection to work with EMAP.\nFor example, let’s inspect patients currently in ED or Resus.\nHere’s the SQL:\n-- Example script \n-- to pick out patients currently in A&E resus or majors\n\nSELECT\n   vd.location_visit_id\n  ,vd.hospital_visit_id\n  ,vd.location_id\n  -- ugly HL7 location string \n  ,lo.location_string\n  -- time admitted to that bed/theatre/scan etc.\n  ,vd.admission_datetime\n  -- time discharged from that bed\n  ,vd.discharge_datetime\n\nFROM star.location_visit vd\n-- location label\nINNER JOIN star.location lo ON vd.location_id = lo.location_id\nWHERE \n-- last few hours\nvd.admission_datetime > NOW() - '12 HOURS'::INTERVAL    \n-- just CURRENT patients\nAND\nvd.discharge_datetime IS NULL\n-- filter out just ED and Resus or Majors\nAND\n-- unpacking the HL7 string formatted as \n-- Department^Ward^Bed string\nSPLIT_PART(lo.location_string,'^',1) = 'ED'\nAND\nSPLIT_PART(lo.location_string,'^',2) ~ '(RESUS|MAJORS)'\n-- sort\nORDER BY lo.location_string\n;\nThe SQL script is stored at ./utils/queries/current_bed.sql.\nWe can load the script, and read the results into a Pandas dataframe.\n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('utils/queries/current_bed.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\n\ndf.head()\n\n\n\n\nA series of three scripts\n\nSimply pull hospital visits\nAdd in hospital numbers (MRN) and handle patient merges\nAdd in patient demographics\n\n\n\nSELECT\n   vo.hospital_visit_id\n  ,vo.encounter\n  -- admission to hospital\n  ,vo.admission_datetime\n  ,vo.arrival_method\n  ,vo.presentation_datetime\n  -- discharge from hospital\n  -- NB: Outpatients have admission events but not discharge events\n  ,vo.discharge_datetime\n  ,vo.discharge_disposition\n\n-- start from hospital visits\nFROM star.hospital_visit vo\nWHERE \n      -- hospital visits within the last 12 hours\n      vo.presentation_datetime > NOW() - '12 HOURS'::INTERVAL   \n      -- emergencies\n  AND vo.patient_class = 'EMERGENCY'\n      -- attending via ambulance\n  AND vo.arrival_method = 'Ambulance'\n      -- sort descending\nORDER BY vo.presentation_datetime DESC\n; \n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('./utils/queries/hospital_visit_1.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\ndf.head()\n\n\n\n\nSee the series of joins in the middle of the script that retrieve the live MRN. That is we recognise that patients may have had an episode of care with one MRN, and then that episode was merged with another historical MRN. One of those two MRNs will then become the ‘live’ MRN and can be used to trace the patient across what otherwise would be different identities.\nSELECT\n   vo.hospital_visit_id\n  ,vo.encounter\n  ,vo.admission_datetime\n  ,vo.arrival_method\n  ,vo.presentation_datetime\n  ,vo.discharge_datetime\n  ,vo.discharge_disposition\n  -- original MRN\n  ,original_mrn.mrn AS original_mrn\n  -- live MRN\n  ,live_mrn.mrn AS live_mrn\n\n-- start from hospital visits\nFROM star.hospital_visit vo\n-- get original mrn\nINNER JOIN star.mrn original_mrn ON vo.mrn_id = original_mrn.mrn_id\n-- get mrn to live mapping \nINNER JOIN star.mrn_to_live mtl ON vo.mrn_id = mtl.mrn_id \n-- get live mrn \nINNER JOIN star.mrn live_mrn ON mtl.live_mrn_id = live_mrn.mrn_id \n\nWHERE \n      -- hospital visits within the last 12 hours\n      vo.presentation_datetime > NOW() - '12 HOURS'::INTERVAL   \n      -- emergencies\n  AND vo.patient_class = 'EMERGENCY'\n      -- attending via ambulance\n  AND vo.arrival_method = 'Ambulance'\n      -- sort descending\nORDER BY vo.presentation_datetime DESC\n; \n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('./utils/queries/hospital_visit_2.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\ndf.head()\n\n\n\n\nSELECT\n   vo.hospital_visit_id\n  ,vo.encounter\n  ,vo.admission_datetime\n  ,vo.arrival_method\n  ,vo.presentation_datetime\n  ,vo.discharge_datetime\n  ,vo.discharge_disposition\n  -- original MRN\n  ,original_mrn.mrn AS original_mrn\n  -- live MRN\n  ,live_mrn.mrn AS live_mrn\n\n  -- core demographics\n  ,cd.date_of_birth\n  -- convert dob to age in years\n  ,date_part('year', AGE(cd.date_of_birth)) AS age\n  ,cd.sex\n  ,cd.home_postcode\n  -- grab initials from first and last name\n  ,CONCAT(LEFT(cd.firstname, 1), LEFT(cd.lastname, 1)) AS initials\n\n-- start from hospital visits\nFROM star.hospital_visit vo\nINNER JOIN star.core_demographic cd ON vo.mrn_id = cd.mrn_id\n\n-- get original mrn\nINNER JOIN star.mrn original_mrn ON vo.mrn_id = original_mrn.mrn_id\n-- get mrn to live mapping \nINNER JOIN star.mrn_to_live mtl ON vo.mrn_id = mtl.mrn_id \n-- get live mrn \nINNER JOIN star.mrn live_mrn ON mtl.live_mrn_id = live_mrn.mrn_id \n\nWHERE \n      -- hospital visits within the last 12 hours\n      vo.presentation_datetime > NOW() - '12 HOURS'::INTERVAL   \n      -- emergencies\n  AND vo.patient_class = 'EMERGENCY'\n      -- attending via ambulance\n  AND vo.arrival_method = 'Ambulance'\n      -- sort descending\nORDER BY vo.presentation_datetime DESC\n; \n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('./utils/queries/hospital_visit_3.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\ndf.head()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HyStakes",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "HyStakes",
    "section": "Section 1",
    "text": "Section 1\nsome text"
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "HyStakes",
    "section": "Section 2",
    "text": "Section 2\nsome more text"
  },
  {
    "objectID": "vignettes/vignettes.html",
    "href": "vignettes/vignettes.html",
    "title": "Vignettes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nExample Jupyter Notebook\n\n\n\n\n\n\nPrepare synthetic data\n\n\n\n\n\n\nWorking with EMAP star\n\n\n\n\n\n\n\n\nNo matching items"
  }
]