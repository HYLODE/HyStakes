[
  {
    "objectID": "vignettes/hello-world.html",
    "href": "vignettes/hello-world.html",
    "title": "HyStakes",
    "section": "",
    "text": "Use this to confirm that your set-up is working. It should open and run from within VSCode, and it should be using the hystakes kernel.\n\nprint('Hello World!')\n\nHello World!"
  },
  {
    "objectID": "vignettes/prepare-synthetic-data.html",
    "href": "vignettes/prepare-synthetic-data.html",
    "title": "HyStakes",
    "section": "",
    "text": "We need synthetic data.\nWe will inspect live data in this notebook, and then derive a short script that will generate suitable dummy data.\nNOTE\nThis notebook will be be run manually.\nThat should happen from the project root directory where the readme.md and the .env file are stored.\nThe following changes to the project root assuming that the notebook kernel is normally starting from the same directory as the notebook itself.\n\n%cd ../..\n\n/data/hymind/home/steve/HyStakes\n\n\n\nimport os\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\nimport sqlalchemy as sa\n\n\n\nLoad environment variables and set-up SQLAlchemy connection engine for the EMAP Star\n\nload_dotenv(dotenv_path=\".env\")\ntry:\n    assert os.getenv(\"DOTENV_FILE_EXISTS\") == 'TRUE'\nexcept AssertionError:\n    print(\"!!! ERROR: check that the .env file exists at the top level of the project\")\n    print(\"!!! ERROR: check that the relative path is correct\")\n\n\n# Construct the PostgreSQL connection\nuds_host = os.getenv('EMAP_DB_HOST')\nuds_name = os.getenv('EMAP_DB_NAME')\nuds_port = os.getenv('EMAP_DB_PORT')\nuds_user = os.getenv('EMAP_DB_USER')\nuds_passwd = os.getenv('EMAP_DB_PASSWORD')\n\nemapdb_engine = sa.create_engine(f'postgresql://{uds_user}:{uds_passwd}@{uds_host}:{uds_port}/{uds_name}')\n\nHere’s the very long query that I built.\nIt selects all patients on tower wards 2 weeks ago (336 hours), and then finds the age (rounded) and the last heart rate. The remaining data has no identifiers.\n\nSELECT\n left(md5(lv.hospital_visit_id::TEXT), 6) id\n--,lv.location_visit_id\n--,lv.admission_datetime admit_dt_bed\n--,lv.discharge_datetime disch_dt_bed\n--,hv.admission_datetime admit_dt_hosp\n--,hv.discharge_datetime disch_dt_hosp\n,ROUND(EXTRACT(epoch FROM \n    (hv.discharge_datetime - (NOW() - '336 HOURS'::INTERVAL)\n    ))/3600) hours_to_discharge\n--,hv.discharge_destination\n--,hv.patient_class\n--,lo.location_string\n,dept.name department\n\n-- include age rounded to 5\n, ROUND(DATE_PART('year',AGE(cd.date_of_birth ))/5) * 5 AGE\n\n-- add last heart rate\n,hr.value_as_real pulse\n--,hr.observation_datetime\n\n\nFROM star.location_visit lv\nLEFT JOIN star.location lo ON lv.location_id = lo.location_id\nLEFT JOIN star.department dept ON lo.department_id = dept.department_id \nLEFT JOIN star.hospital_visit hv ON lv.hospital_visit_id = hv.hospital_visit_id\nLEFT JOIN star.core_demographic cd ON hv.mrn_id = cd.mrn_id\nLEFT JOIN (\n    WITH obs AS (\n        SELECT\n\n         vo.visit_observation_id\n        ,vo.hospital_visit_id\n        ,vo.observation_datetime\n        ,vo.value_as_real\n        ,ot.name\n\n        FROM star.visit_observation vo\n        LEFT JOIN star.visit_observation_type ot ON vo.visit_observation_type_id = ot.visit_observation_type_id\n        WHERE \n        ot.id_in_application = '8' -- heart rate\n        AND\n        vo.observation_datetime < NOW() - '336 HOURS'::INTERVAL \n        AND\n        vo.observation_datetime > NOW() - '360 HOURS'::INTERVAL \n    ),\n    obs_tail AS (\n        SELECT \n         obs.*\n        ,row_number() over (partition BY obs.hospital_visit_id ORDER BY obs.observation_datetime DESC) obs_tail\n        FROM obs\n    )\n    SELECT \n     visit_observation_id\n    ,hospital_visit_id\n    ,observation_datetime\n    ,value_as_real\n    ,NAME\n    FROM obs_tail \n    WHERE obs_tail = 1\n) hr -- heart rate\nON lv.hospital_visit_id = hr.hospital_visit_id\n\nWHERE \ndept.name IN (\n'UCH T03 INTENSIVE CARE'\n,'UCH SDEC'\n,'UCH T01 ACUTE MEDICAL'\n,'UCH T01 ENHANCED CARE'\n,'UCH T06 HEAD (T06H)'\n,'UCH T06 CENTRAL (T06C)'\n,'UCH T06 SOUTH PACU'\n,'UCH T06 GYNAE (T06G)'\n,'UCH T07 NORTH (T07N)'\n,'UCH T07 CV SURGE'\n,'UCH T07 SOUTH'\n,'UCH T07 SOUTH (T07S)'\n,'UCH T07 HDRU'\n,'UCH T08 NORTH (T08N)'\n,'UCH T08 SOUTH (T08S)'\n,'UCH T08S ARCU'\n,'UCH T09 SOUTH (T09S)'\n,'UCH T09 NORTH (T09N)'\n,'UCH T09 CENTRAL (T09C)'\n,'UCH T10 SOUTH (T10S)'\n,'UCH T10 NORTH (T10N)'\n,'UCH T10 MED (T10M)'\n,'UCH T11 SOUTH (T11S)'\n,'UCH T11 NORTH (T11N)'\n,'UCH T11 EAST (T11E)'\n,'UCH T11 NORTH (T11NO)'\n,'UCH T12 SOUTH (T12S)'\n,'UCH T12 NORTH (T12N)'\n,'UCH T13 SOUTH (T13S)'\n,'UCH T13 NORTH ONCOLOGY'\n,'UCH T13 NORTH (T13N)'\n,'UCH T14 NORTH TRAUMA'\n,'UCH T14 NORTH (T14N)'\n,'UCH T14 SOUTH ASU'\n,'UCH T14 SOUTH (T14S)'\n,'UCH T15 SOUTH DECANT'\n,'UCH T15 SOUTH (T15S)'\n,'UCH T15 NORTH (T15N)'\n,'UCH T15 NORTH DECANT'\n,'UCH T16 NORTH (T16N)'\n,'UCH T16 SOUTH (T16S)'\n,'UCH T16 SOUTH WINTER'\n\n)\nAND\nlv.admission_datetime < NOW() - '336 HOURS'::INTERVAL \nAND\n    (lv.discharge_datetime > NOW() - '336 HOURS'::INTERVAL \n     OR\n      (lv.discharge_datetime IS NULL AND hv.discharge_datetime IS NULL)\n    )\nAND \nlo.location_string NOT LIKE '%WAIT%'\nAND \nlo.location_string NOT LIKE '%null%'\n;\n\nq = Path('utils/queries/discharges_dummy.sql').read_text()\n\n# this handles escaping etc (e.g. % should be %%)\nq = sa.text(q)\n\n\ndf = pd.read_sql_query(q, emapdb_engine)\n\n\ndf.head()\n\n\ndf.department.value_counts()\n\nUCH T10 SOUTH (T10S)      34\nUCH T01 ACUTE MEDICAL     33\nUCH SDEC                  30\nUCH T09 NORTH (T09N)      26\nUCH T03 INTENSIVE CARE    25\nUCH T10 NORTH (T10N)      23\nUCH T13 SOUTH (T13S)      22\nUCH T13 NORTH ONCOLOGY    22\nUCH T07 NORTH (T07N)      19\nUCH T09 CENTRAL (T09C)    19\nUCH T08 SOUTH (T08S)      19\nUCH T08 NORTH (T08N)      18\nUCH T16 NORTH (T16N)      16\nUCH T14 NORTH TRAUMA      15\nUCH T12 NORTH (T12N)      15\nUCH T14 SOUTH ASU         14\nUCH T16 SOUTH WINTER      14\nUCH T06 HEAD (T06H)       14\nUCH T01 ENHANCED CARE     14\nUCH T12 SOUTH (T12S)      11\nUCH T11 NORTH (T11N)      10\nUCH T07 SOUTH             10\nUCH T06 SOUTH PACU         9\nUCH T06 CENTRAL (T06C)     9\nUCH T11 SOUTH (T11S)       9\nUCH T14 NORTH (T14N)       4\nUCH T06 GYNAE (T06G)       3\nUCH T09 SOUTH (T09S)       3\nUCH T07 SOUTH (T07S)       2\nUCH T15 SOUTH (T15S)       2\nUCH T10 MED (T10M)         1\nUCH T08S ARCU              1\nUCH T15 NORTH (T15N)       1\nUCH T16 SOUTH (T16S)       1\nName: department, dtype: int64\n\n\n\npx.histogram(df.age)\n\n\n                                                \n\n\n\npx.histogram(df.pulse)\n\n\n                                                \n\n\n\ndf.hours_to_discharge\n\n0       16.0\n1      324.0\n2        NaN\n3       17.0\n4        NaN\n       ...  \n463     17.0\n464     17.0\n465      NaN\n466     17.0\n467    284.0\nName: hours_to_discharge, Length: 468, dtype: float64\n\n\n\npx.histogram(df.hours_to_discharge)"
  },
  {
    "objectID": "vignettes/uclh-working-with-star.html",
    "href": "vignettes/uclh-working-with-star.html",
    "title": "HyStakes",
    "section": "",
    "text": "A template JupyterNotebook for working with EMAP. The following features of this notebook, and associated files are documented here to minimise the risk of data leaks or other incidents.\n\nUsernames and passwords are stored in a .env file that is excluded from version control. An example file is found at ./.env.example (which is tracked and shared via version control).\n.gitattributes are set to strip JupyterNotebook cells when pushing to GitHub\n\nNOTE\nThis notebook will be be run manually.\nThat should happen from the project root directory where the readme.md and the .env file are stored.\nThe following changes to the project root assuming that the notebook kernel is normally starting from the same directory as the notebook itself.\n\n%cd ../..\n\n\n\nLoad libraries\n\nimport os\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n\n\n\nLoad environment variables and set-up SQLAlchemy connection engine for the EMAP Star\n\nload_dotenv(dotenv_path=\".env\")\ntry:\n    assert os.getenv(\"DOTENV_FILE_EXISTS\") == 'TRUE'\nexcept AssertionError:\n    print(\"!!! ERROR: check that the .env file exists at the top level of the project\")\n    print(\"!!! ERROR: check that the relative path is correct\")\n\n\n# Construct the PostgreSQL connection\nuds_host = os.getenv('EMAP_DB_HOST')\nuds_name = os.getenv('EMAP_DB_NAME')\nuds_port = os.getenv('EMAP_DB_PORT')\nuds_user = os.getenv('EMAP_DB_USER')\nuds_passwd = os.getenv('EMAP_DB_PASSWORD')\n\nemapdb_engine = create_engine(f'postgresql://{uds_user}:{uds_passwd}@{uds_host}:{uds_port}/{uds_name}')\n\n\n\n\nNow use the connection to work with EMAP.\nFor example, let’s inspect patients currently in ED or Resus.\nHere’s the SQL:\n-- Example script \n-- to pick out patients currently in A&E resus or majors\n\nSELECT\n   vd.location_visit_id\n  ,vd.hospital_visit_id\n  ,vd.location_id\n  -- ugly HL7 location string \n  ,lo.location_string\n  -- time admitted to that bed/theatre/scan etc.\n  ,vd.admission_datetime\n  -- time discharged from that bed\n  ,vd.discharge_datetime\n\nFROM star.location_visit vd\n-- location label\nINNER JOIN star.location lo ON vd.location_id = lo.location_id\nWHERE \n-- last few hours\nvd.admission_datetime > NOW() - '12 HOURS'::INTERVAL    \n-- just CURRENT patients\nAND\nvd.discharge_datetime IS NULL\n-- filter out just ED and Resus or Majors\nAND\n-- unpacking the HL7 string formatted as \n-- Department^Ward^Bed string\nSPLIT_PART(lo.location_string,'^',1) = 'ED'\nAND\nSPLIT_PART(lo.location_string,'^',2) ~ '(RESUS|MAJORS)'\n-- sort\nORDER BY lo.location_string\n;\nThe SQL script is stored at ./utils/queries/current_bed.sql.\nWe can load the script, and read the results into a Pandas dataframe.\n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('utils/queries/current_bed.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\n\ndf.head()\n\n\n\n\nA series of three scripts\n\nSimply pull hospital visits\nAdd in hospital numbers (MRN) and handle patient merges\nAdd in patient demographics\n\n\n\nSELECT\n   vo.hospital_visit_id\n  ,vo.encounter\n  -- admission to hospital\n  ,vo.admission_datetime\n  ,vo.arrival_method\n  ,vo.presentation_datetime\n  -- discharge from hospital\n  -- NB: Outpatients have admission events but not discharge events\n  ,vo.discharge_datetime\n  ,vo.discharge_disposition\n\n-- start from hospital visits\nFROM star.hospital_visit vo\nWHERE \n      -- hospital visits within the last 12 hours\n      vo.presentation_datetime > NOW() - '12 HOURS'::INTERVAL   \n      -- emergencies\n  AND vo.patient_class = 'EMERGENCY'\n      -- attending via ambulance\n  AND vo.arrival_method = 'Ambulance'\n      -- sort descending\nORDER BY vo.presentation_datetime DESC\n; \n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('./utils/queries/hospital_visit_1.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\ndf.head()\n\n\n\n\nSee the series of joins in the middle of the script that retrieve the live MRN. That is we recognise that patients may have had an episode of care with one MRN, and then that episode was merged with another historical MRN. One of those two MRNs will then become the ‘live’ MRN and can be used to trace the patient across what otherwise would be different identities.\nSELECT\n   vo.hospital_visit_id\n  ,vo.encounter\n  ,vo.admission_datetime\n  ,vo.arrival_method\n  ,vo.presentation_datetime\n  ,vo.discharge_datetime\n  ,vo.discharge_disposition\n  -- original MRN\n  ,original_mrn.mrn AS original_mrn\n  -- live MRN\n  ,live_mrn.mrn AS live_mrn\n\n-- start from hospital visits\nFROM star.hospital_visit vo\n-- get original mrn\nINNER JOIN star.mrn original_mrn ON vo.mrn_id = original_mrn.mrn_id\n-- get mrn to live mapping \nINNER JOIN star.mrn_to_live mtl ON vo.mrn_id = mtl.mrn_id \n-- get live mrn \nINNER JOIN star.mrn live_mrn ON mtl.live_mrn_id = live_mrn.mrn_id \n\nWHERE \n      -- hospital visits within the last 12 hours\n      vo.presentation_datetime > NOW() - '12 HOURS'::INTERVAL   \n      -- emergencies\n  AND vo.patient_class = 'EMERGENCY'\n      -- attending via ambulance\n  AND vo.arrival_method = 'Ambulance'\n      -- sort descending\nORDER BY vo.presentation_datetime DESC\n; \n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('./utils/queries/hospital_visit_2.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\ndf.head()\n\n\n\n\nSELECT\n   vo.hospital_visit_id\n  ,vo.encounter\n  ,vo.admission_datetime\n  ,vo.arrival_method\n  ,vo.presentation_datetime\n  ,vo.discharge_datetime\n  ,vo.discharge_disposition\n  -- original MRN\n  ,original_mrn.mrn AS original_mrn\n  -- live MRN\n  ,live_mrn.mrn AS live_mrn\n\n  -- core demographics\n  ,cd.date_of_birth\n  -- convert dob to age in years\n  ,date_part('year', AGE(cd.date_of_birth)) AS age\n  ,cd.sex\n  ,cd.home_postcode\n  -- grab initials from first and last name\n  ,CONCAT(LEFT(cd.firstname, 1), LEFT(cd.lastname, 1)) AS initials\n\n-- start from hospital visits\nFROM star.hospital_visit vo\nINNER JOIN star.core_demographic cd ON vo.mrn_id = cd.mrn_id\n\n-- get original mrn\nINNER JOIN star.mrn original_mrn ON vo.mrn_id = original_mrn.mrn_id\n-- get mrn to live mapping \nINNER JOIN star.mrn_to_live mtl ON vo.mrn_id = mtl.mrn_id \n-- get live mrn \nINNER JOIN star.mrn live_mrn ON mtl.live_mrn_id = live_mrn.mrn_id \n\nWHERE \n      -- hospital visits within the last 12 hours\n      vo.presentation_datetime > NOW() - '12 HOURS'::INTERVAL   \n      -- emergencies\n  AND vo.patient_class = 'EMERGENCY'\n      -- attending via ambulance\n  AND vo.arrival_method = 'Ambulance'\n      -- sort descending\nORDER BY vo.presentation_datetime DESC\n; \n\n# Read the sql file into a query 'q' and the query into a dataframe\nq = Path('./utils/queries/hospital_visit_3.sql').read_text()\ndf = pd.read_sql_query(q, emapdb_engine)\n\ndf.head()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HyStakes",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "HyStakes",
    "section": "Section 1",
    "text": "Section 1\nsome text"
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "HyStakes",
    "section": "Section 2",
    "text": "Section 2\nsome more text"
  },
  {
    "objectID": "vignettes/vignettes.html",
    "href": "vignettes/vignettes.html",
    "title": "Vignettes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nExample Jupyter Notebook\n\n\n\n\n\n\nPrepare synthetic data\n\n\n\n\n\n\nWorking with EMAP star\n\n\n\n\n\n\n\n\nNo matching items"
  }
]